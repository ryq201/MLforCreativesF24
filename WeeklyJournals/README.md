# Weekly Journals

## Week 1

After experimenting with the examples for a bit, I was impressed with the overall level of accuracy the model had. However, there were obvious hiccups and mistakes. Sometimes the correct identification was not the most confident classification, while other instances it would fail to identify something completely. One example was a picture of my trash can, which is a standard white plastic bin with a plastic bag lining the inside. Although I thought this prompt would be easy enough, it would not classify it as a trash can. Another quirk I noticed is that sometimes I would upload a picture of something hoping it would identify the object in the foreground, but it would instead identify something else that I did not intend to be the focus. 

Taking a look at the data set links provided, it was interesting to see the wide variety of objects these models are trained to identify. I found myself wondering however if there was enough variety of each type of object, animal, etc. What if the lighting or angle was different, or maybe the object had a different color or design? Some of the images also did not seem to be completely obvious in their relation to ID, which made me wonder about potential biases some may have about what classifies as a certain thing, and how this could affect the model. 
